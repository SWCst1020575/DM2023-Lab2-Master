{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 蘇暐中\n",
    "\n",
    "Student ID: 109020021\n",
    "\n",
    "GitHub ID: SWCst1020575\n",
    "\n",
    "Kaggle name (Group): 這是一個整人的活動嗎？笑死人喔？主辦單位，出來解釋一下好不好\n",
    "\n",
    "Kaggle name (User): Wei-Chung Su\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "![Snapshot](../pics/kaggle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the DM2023-Lab2-master. You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/t/09b1d0f3f8584d06848252277cb535f2) regarding Emotion Recognition on Twitter by this link https://www.kaggle.com/t/09b1d0f3f8584d06848252277cb535f2. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "    Submit your last submission __BEFORE the deadline (Dec. 27th 11:59 pm, Wednesday)_. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Dec. 31th 11:59 pm, Sunday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_identification = pd.read_csv(\"data_identification.csv\")\n",
    "emotion = pd.read_csv(\"emotion.csv\")\n",
    "tweets_DM = pd.read_json(\"tweets_DM.json\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_DM[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets_DM[\"_index\"].value_counts())\n",
    "print(tweets_DM[\"_type\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which implies _index and _type have exact 1 type of value. Therefore, we drop these two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_drop = tweets_DM.drop(columns=[\"_index\",\"_type\"],axis=1)\n",
    "tweets_drop[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "{   // _source structure\n",
    "    \"tweet\":{\n",
    "        \"hashtags\":[\"tag\",\"tag\"],\n",
    "        \"tweet_id\":\"hash\",\n",
    "        \"text\": \"post content ...\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract dict from _source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = [ np.array(row['tweet']['hashtags']) for row in tweets_drop.values[:,1][:,] ]\n",
    "tweet_id = [ row['tweet']['tweet_id'] for row in tweets_drop.values[:,1][:,]]\n",
    "text = [ row['tweet']['text'] for row in tweets_drop.values[:,1][:,]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.concat([tweets_drop,pd.Series(hashtags).to_frame(\"hashtags\")\n",
    "                    ,pd.Series(tweet_id).to_frame(\"tweet_id\"),\n",
    "                    pd.Series(text).to_frame(\"text\")],axis=1)\n",
    "tweets.drop(columns=[\"_source\"],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove @username, link and #tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textPreprocessing(processingData):\n",
    "    text = processingData[\"text\"]\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = '' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    while \"<LH>\" in new_text:\n",
    "        new_text.remove(\"<LH>\")\n",
    "    new_text = \" \".join(new_text)\n",
    "    for tag in processingData[\"hashtags\"]:\n",
    "        new_text = new_text.replace(f\"#{tag}\",\"\")\n",
    "    processingData[\"text\"] = new_text\n",
    "    return processingData\n",
    "# tweets[\"text\"] = tweets[\"text\"].apply(textPreprocessing)\n",
    "tweets = tweets.apply(textPreprocessing,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine data and split train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_identification = pd.merge(tweets,data_identification,on=\"tweet_id\")\n",
    "tweets_identification.drop(\"hashtags\",axis=1,inplace=True)\n",
    "tweets_train = tweets_identification[tweets_identification[\"identification\"] == \"train\"]\n",
    "tweets_test = tweets_identification[tweets_identification[\"identification\"] == \"test\"]\n",
    "tweets_train = pd.merge(tweets_train,emotion,on=\"tweet_id\")\n",
    "tweets_train.drop(\"identification\",axis=1,inplace=True)\n",
    "tweets_test.drop(\"identification\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_y = tweets_train[\"emotion\"]\n",
    "# tweets_train.drop(\"emotion\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(tweets_train.drop([\"tweet_id\",\"_crawldate\",\"_score\"],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "emotionEncoder = OneHotEncoder()\n",
    "emotionEncoder.fit(tweets_y.to_numpy().reshape(-1,1))\n",
    "y = emotionEncoder.transform(tweets_y.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification,RobertaTokenizerFast\n",
    "model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion-latest', num_labels=8, ignore_mismatched_sizes=True).to(device)\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    newDict = {}\n",
    "    text_tokenized = tokenizer(data[\"text\"])\n",
    "    labels = emotionEncoder.transform(np.array(data[\"emotion\"]).reshape(-1,1))\n",
    "    newDict[\"input_ids\"] = text_tokenized[\"input_ids\"]\n",
    "    newDict[\"attention_mask\"] = text_tokenized[\"attention_mask\"]\n",
    "    newDict[\"label\"] = labels.toarray()\n",
    "    return newDict\n",
    "preprocessed = dataset.map(preprocess,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = preprocessed.train_test_split(test_size=0.005,seed=42)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.argmax(-1)\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results-latest-removeTag',\n",
    "    num_train_epochs=3,\n",
    "    learning_rate = 6e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=2500,\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    metric_for_best_model=\"f1\",\n",
    "    save_steps=5000,\n",
    "    eval_accumulation_steps=1,\n",
    "    fp16=True,\n",
    "    fp16_full_eval =True\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(\"./results-latest-removeTag/checkpoint-100000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predPreprocess(data):\n",
    "    newDict = {}\n",
    "    text_tokenized = tokenizer(data[\"text\"])\n",
    "    newDict[\"input_ids\"] = text_tokenized[\"input_ids\"]\n",
    "    newDict[\"attention_mask\"] = text_tokenized[\"attention_mask\"]\n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = Dataset.from_pandas(tweets_test.drop([\"tweet_id\",\"_crawldate\",\"_score\"],axis=1))\n",
    "pred_preprocessed = pred_dataset.map(predPreprocess,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model = RobertaForSequenceClassification.from_pretrained('./results-latest-removeTag/checkpoint-110000', num_labels=8, ignore_mismatched_sizes=True).to(device)\n",
    "pred_trainer = Trainer(\n",
    "        model=pred_model,\n",
    "        args=training_args,\n",
    "        train_dataset=None,\n",
    "        eval_dataset=None,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions, labels, metrics = trainer.predict(pred_preprocessed)\n",
    "predictions, labels, metrics = pred_trainer.predict(pred_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.from_numpy(predictions)\n",
    "pred_result = torch.argmax(predictions,dim=1).to(device)\n",
    "pred_labels = torch.nn.functional.one_hot(pred_result)\n",
    "pred_emotion = emotionEncoder.inverse_transform(pred_labels.cpu()).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_emotion = np.concatenate([tweets_test[\"tweet_id\"].to_numpy().reshape(-1,1),pred_emotion.reshape(-1,1)],axis=1)\n",
    "id_emotion = pd.DataFrame(id_emotion,columns=[\"id\",\"emotion\"])\n",
    "sample = pd.read_csv(\"sampleSubmission.csv\").drop(\"emotion\",axis=1)\n",
    "output = pd.merge(sample,id_emotion,on=\"id\")\n",
    "output.to_csv(\"output.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
