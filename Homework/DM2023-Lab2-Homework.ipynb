{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 蘇暐中\n",
    "\n",
    "Student ID: 109020021\n",
    "\n",
    "GitHub ID: SWCst1020575\n",
    "\n",
    "Kaggle name (Group): 這是一個整人的活動嗎？笑死人喔？主辦單位，出來解釋一下好不好\n",
    "\n",
    "Kaggle name (User): Wei-Chung Su\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the DM2023-Lab2-master. You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/t/09b1d0f3f8584d06848252277cb535f2) regarding Emotion Recognition on Twitter by this link https://www.kaggle.com/t/09b1d0f3f8584d06848252277cb535f2. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "    Submit your last submission __BEFORE the deadline (Dec. 27th 11:59 pm, Wednesday)_. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Dec. 31th 11:59 pm, Sunday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_identification = pd.read_csv(\"data_identification.csv\")\n",
    "emotion = pd.read_csv(\"emotion.csv\")\n",
    "tweets_DM = pd.read_json(\"tweets_DM.json\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_index</th>\n",
       "      <th>_source</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['Snapchat'], 'tweet_id...</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['freepress', 'TrumpLeg...</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['bibleverse'], 'tweet_...</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2de2...</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _score          _index                                            _source  \\\n",
       "0     391  hashtag_tweets  {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...   \n",
       "1     433  hashtag_tweets  {'tweet': {'hashtags': ['freepress', 'TrumpLeg...   \n",
       "2     232  hashtag_tweets  {'tweet': {'hashtags': ['bibleverse'], 'tweet_...   \n",
       "3     376  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...   \n",
       "4     989  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...   \n",
       "\n",
       "            _crawldate   _type  \n",
       "0  2015-05-23 11:42:47  tweets  \n",
       "1  2016-01-28 04:52:09  tweets  \n",
       "2  2017-12-25 04:39:20  tweets  \n",
       "3  2016-01-24 23:53:05  tweets  \n",
       "4  2016-01-08 17:18:59  tweets  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_DM[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_index\n",
      "hashtag_tweets    1867535\n",
      "Name: count, dtype: int64\n",
      "_type\n",
      "tweets    1867535\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweets_DM[\"_index\"].value_counts())\n",
    "print(tweets_DM[\"_type\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which implies _index and _type have exact 1 type of value. Therefore, we drop these two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_source</th>\n",
       "      <th>_crawldate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>{'tweet': {'hashtags': ['Snapchat'], 'tweet_id...</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>{'tweet': {'hashtags': ['freepress', 'TrumpLeg...</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>{'tweet': {'hashtags': ['bibleverse'], 'tweet_...</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2de2...</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _score                                            _source  \\\n",
       "0     391  {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...   \n",
       "1     433  {'tweet': {'hashtags': ['freepress', 'TrumpLeg...   \n",
       "2     232  {'tweet': {'hashtags': ['bibleverse'], 'tweet_...   \n",
       "3     376  {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...   \n",
       "4     989  {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...   \n",
       "\n",
       "            _crawldate  \n",
       "0  2015-05-23 11:42:47  \n",
       "1  2016-01-28 04:52:09  \n",
       "2  2017-12-25 04:39:20  \n",
       "3  2016-01-24 23:53:05  \n",
       "4  2016-01-08 17:18:59  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_drop = tweets_DM.drop(columns=[\"_index\",\"_type\"],axis=1)\n",
    "tweets_drop[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "{   // _source structure\n",
    "    \"tweet\":{\n",
    "        \"hashtags\":[\"tag\",\"tag\"],\n",
    "        \"tweet_id\":\"hash\",\n",
    "        \"text\": \"post content ...\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract dict from _source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = [ np.array(row['tweet']['hashtags']) for row in tweets_drop.values[:,1][:,] ]\n",
    "tweet_id = [ row['tweet']['tweet_id'] for row in tweets_drop.values[:,1][:,]]\n",
    "text = [ row['tweet']['text'] for row in tweets_drop.values[:,1][:,]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.concat([tweets_drop,pd.Series(hashtags).to_frame(\"hashtags\")\n",
    "                    ,pd.Series(tweet_id).to_frame(\"tweet_id\"),\n",
    "                    pd.Series(text).to_frame(\"text\")],axis=1)\n",
    "tweets.drop(columns=[\"_source\"],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove @username, link and #tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textPreprocessing(processingData):\n",
    "    text = processingData[\"text\"]\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = '' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    while \"<LH>\" in new_text:\n",
    "        new_text.remove(\"<LH>\")\n",
    "    new_text = \" \".join(new_text)\n",
    "    for tag in processingData[\"hashtags\"]:\n",
    "        new_text = new_text.replace(f\"#{tag}\",\"\")\n",
    "    processingData[\"text\"] = new_text\n",
    "    return processingData\n",
    "# tweets[\"text\"] = tweets[\"text\"].apply(textPreprocessing)\n",
    "tweets = tweets.apply(textPreprocessing,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine data and split train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18458/3920154719.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_test.drop(\"identification\",axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "tweets_identification = pd.merge(tweets,data_identification,on=\"tweet_id\")\n",
    "tweets_identification.drop(\"hashtags\",axis=1,inplace=True)\n",
    "tweets_train = tweets_identification[tweets_identification[\"identification\"] == \"train\"]\n",
    "tweets_test = tweets_identification[tweets_identification[\"identification\"] == \"test\"]\n",
    "tweets_train = pd.merge(tweets_train,emotion,on=\"tweet_id\")\n",
    "tweets_train.drop(\"identification\",axis=1,inplace=True)\n",
    "tweets_test.drop(\"identification\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_y = tweets_train[\"emotion\"]\n",
    "# tweets_train.drop(\"emotion\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swc/DM/DM2023-Lab2-Master/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(tweets_train.drop([\"tweet_id\",\"_crawldate\",\"_score\"],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "emotionEncoder = OneHotEncoder()\n",
    "emotionEncoder.fit(tweets_y.to_numpy().reshape(-1,1))\n",
    "y = emotionEncoder.transform(tweets_y.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-27 23:19:29,602] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion-latest and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification,RobertaTokenizerFast\n",
    "model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-emotion-latest', num_labels=8, ignore_mismatched_sizes=True).to(device)\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1455563 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1455563/1455563 [00:22<00:00, 65221.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess(data):\n",
    "    newDict = {}\n",
    "    text_tokenized = tokenizer(data[\"text\"])\n",
    "    labels = emotionEncoder.transform(np.array(data[\"emotion\"]).reshape(-1,1))\n",
    "    newDict[\"input_ids\"] = text_tokenized[\"input_ids\"]\n",
    "    newDict[\"attention_mask\"] = text_tokenized[\"attention_mask\"]\n",
    "    newDict[\"label\"] = labels.toarray()\n",
    "    return newDict\n",
    "preprocessed = dataset.map(preprocess,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'emotion', 'input_ids', 'attention_mask', 'label'],\n",
       "        num_rows: 1448285\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'emotion', 'input_ids', 'attention_mask', 'label'],\n",
       "        num_rows: 7278\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = preprocessed.train_test_split(test_size=0.005,seed=42)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.argmax(-1)\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results-latest-removeTag',\n",
    "    num_train_epochs=3,\n",
    "    learning_rate = 6e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=2500,\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    metric_for_best_model=\"f1\",\n",
    "    save_steps=50000,\n",
    "    eval_accumulation_steps=1,\n",
    "    fp16=True,\n",
    "    fp16_full_eval =True\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100376' max='135777' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100376/135777 3:15:55 < 1:09:06, 8.54 it/s, Epoch 2.22/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>0.256484</td>\n",
       "      <td>0.518686</td>\n",
       "      <td>0.498651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.256000</td>\n",
       "      <td>0.252908</td>\n",
       "      <td>0.538335</td>\n",
       "      <td>0.502553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.250300</td>\n",
       "      <td>0.248431</td>\n",
       "      <td>0.537785</td>\n",
       "      <td>0.512732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.247769</td>\n",
       "      <td>0.547678</td>\n",
       "      <td>0.520419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.245299</td>\n",
       "      <td>0.544518</td>\n",
       "      <td>0.511506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.241500</td>\n",
       "      <td>0.241737</td>\n",
       "      <td>0.550838</td>\n",
       "      <td>0.539969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.240600</td>\n",
       "      <td>0.238696</td>\n",
       "      <td>0.561968</td>\n",
       "      <td>0.540291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>0.236003</td>\n",
       "      <td>0.565265</td>\n",
       "      <td>0.548345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.241216</td>\n",
       "      <td>0.563479</td>\n",
       "      <td>0.543788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.233707</td>\n",
       "      <td>0.571173</td>\n",
       "      <td>0.548562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.234900</td>\n",
       "      <td>0.239036</td>\n",
       "      <td>0.559357</td>\n",
       "      <td>0.543725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.233600</td>\n",
       "      <td>0.233178</td>\n",
       "      <td>0.568013</td>\n",
       "      <td>0.551496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.232600</td>\n",
       "      <td>0.234781</td>\n",
       "      <td>0.563754</td>\n",
       "      <td>0.552957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.233093</td>\n",
       "      <td>0.571173</td>\n",
       "      <td>0.554050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.230700</td>\n",
       "      <td>0.230429</td>\n",
       "      <td>0.577082</td>\n",
       "      <td>0.563485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.230700</td>\n",
       "      <td>0.230293</td>\n",
       "      <td>0.579830</td>\n",
       "      <td>0.563747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.229345</td>\n",
       "      <td>0.577494</td>\n",
       "      <td>0.555180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.230100</td>\n",
       "      <td>0.232424</td>\n",
       "      <td>0.580104</td>\n",
       "      <td>0.565668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.232078</td>\n",
       "      <td>0.575982</td>\n",
       "      <td>0.560723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.228839</td>\n",
       "      <td>0.573097</td>\n",
       "      <td>0.562324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52500</td>\n",
       "      <td>0.217400</td>\n",
       "      <td>0.228824</td>\n",
       "      <td>0.582715</td>\n",
       "      <td>0.569410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.217400</td>\n",
       "      <td>0.228721</td>\n",
       "      <td>0.576944</td>\n",
       "      <td>0.566610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57500</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.229431</td>\n",
       "      <td>0.584776</td>\n",
       "      <td>0.574443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.216300</td>\n",
       "      <td>0.226998</td>\n",
       "      <td>0.583402</td>\n",
       "      <td>0.568864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>0.216200</td>\n",
       "      <td>0.224739</td>\n",
       "      <td>0.583952</td>\n",
       "      <td>0.564639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.224212</td>\n",
       "      <td>0.585600</td>\n",
       "      <td>0.569645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67500</td>\n",
       "      <td>0.214700</td>\n",
       "      <td>0.225349</td>\n",
       "      <td>0.587112</td>\n",
       "      <td>0.575262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>0.225213</td>\n",
       "      <td>0.583814</td>\n",
       "      <td>0.571832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72500</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.224553</td>\n",
       "      <td>0.590409</td>\n",
       "      <td>0.580942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.214300</td>\n",
       "      <td>0.221139</td>\n",
       "      <td>0.590959</td>\n",
       "      <td>0.579906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77500</td>\n",
       "      <td>0.213300</td>\n",
       "      <td>0.225225</td>\n",
       "      <td>0.589448</td>\n",
       "      <td>0.579652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.222024</td>\n",
       "      <td>0.592196</td>\n",
       "      <td>0.583832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82500</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.222903</td>\n",
       "      <td>0.595218</td>\n",
       "      <td>0.587495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.212900</td>\n",
       "      <td>0.220769</td>\n",
       "      <td>0.596730</td>\n",
       "      <td>0.587854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87500</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>0.221435</td>\n",
       "      <td>0.598379</td>\n",
       "      <td>0.588327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.211500</td>\n",
       "      <td>0.219986</td>\n",
       "      <td>0.600302</td>\n",
       "      <td>0.589864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92500</td>\n",
       "      <td>0.199800</td>\n",
       "      <td>0.224348</td>\n",
       "      <td>0.597692</td>\n",
       "      <td>0.591861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>0.226106</td>\n",
       "      <td>0.596180</td>\n",
       "      <td>0.584357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97500</td>\n",
       "      <td>0.195400</td>\n",
       "      <td>0.222922</td>\n",
       "      <td>0.599478</td>\n",
       "      <td>0.590906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.195500</td>\n",
       "      <td>0.222340</td>\n",
       "      <td>0.597554</td>\n",
       "      <td>0.593289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DM/DM2023-Lab2-Master/.venv/lib/python3.8/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DM/DM2023-Lab2-Master/.venv/lib/python3.8/site-packages/transformers/trainer.py:1838\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1835\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1837\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1838\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1839\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[0;32m~/DM/DM2023-Lab2-Master/.venv/lib/python3.8/site-packages/accelerate/data_loader.py:393\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 393\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n",
      "File \u001b[0;32m~/DM/DM2023-Lab2-Master/.venv/lib/python3.8/site-packages/accelerate/utils/operations.py:160\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[0;32m--> 160\u001b[0m         {\n\u001b[1;32m    161\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m send_to_device(t, device, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking, skip_keys\u001b[38;5;241m=\u001b[39mskip_keys)\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    163\u001b[0m         }\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/DM/DM2023-Lab2-Master/.venv/lib/python3.8/site-packages/accelerate/utils/operations.py:161\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[1;32m    160\u001b[0m         {\n\u001b[0;32m--> 161\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    163\u001b[0m         }\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/DM/DM2023-Lab2-Master/.venv/lib/python3.8/site-packages/accelerate/utils/operations.py:167\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predPreprocess(data):\n",
    "    newDict = {}\n",
    "    text_tokenized = tokenizer(data[\"text\"])\n",
    "    newDict[\"input_ids\"] = text_tokenized[\"input_ids\"]\n",
    "    newDict[\"attention_mask\"] = text_tokenized[\"attention_mask\"]\n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 411972/411972 [00:06<00:00, 59772.24 examples/s]\n"
     ]
    }
   ],
   "source": [
    "pred_dataset = Dataset.from_pandas(tweets_test.drop([\"tweet_id\",\"_crawldate\",\"_score\"],axis=1))\n",
    "pred_preprocessed = pred_dataset.map(predPreprocess,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model = RobertaForSequenceClassification.from_pretrained('./results-latest-removeTag/checkpoint-100000', num_labels=8, ignore_mismatched_sizes=True).to(device)\n",
    "pred_trainer = Trainer(\n",
    "        model=pred_model,\n",
    "        args=training_args,\n",
    "        train_dataset=None,\n",
    "        eval_dataset=None,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predictions, labels, metrics = trainer.predict(pred_preprocessed)\n",
    "predictions, labels, metrics = pred_trainer.predict(pred_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.from_numpy(predictions)\n",
    "pred_result = torch.argmax(predictions,dim=1).to(device)\n",
    "pred_labels = torch.nn.functional.one_hot(pred_result)\n",
    "pred_emotion = emotionEncoder.inverse_transform(pred_labels.cpu()).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_emotion = np.concatenate([tweets_test[\"tweet_id\"].to_numpy().reshape(-1,1),pred_emotion.reshape(-1,1)],axis=1)\n",
    "id_emotion = pd.DataFrame(id_emotion,columns=[\"id\",\"emotion\"])\n",
    "sample = pd.read_csv(\"sampleSubmission.csv\").drop(\"emotion\",axis=1)\n",
    "output = pd.merge(sample,id_emotion,on=\"id\")\n",
    "output.to_csv(\"output.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
